ğŸš¨ Unified Threat Defense - SystÃ¨me de DÃ©tection de Fraude en Temps RÃ©el
https://img.shields.io/badge/version-1.0.0-blue.svg
https://img.shields.io/badge/docker-%253E%253D20.0-green.svg
https://img.shields.io/badge/Apache%2520Spark-3.4.3-orange.svg

ğŸ“‹ Table des MatiÃ¨res
AperÃ§u

Architecture

PrÃ©requis

Installation

Utilisation

Structure du Projet

API et Endpoints

Monitoring

DÃ©pannage

Contribuer

Licence

ğŸ¯ AperÃ§u
Unified Threat Defense est une plateforme complÃ¨te de dÃ©tection de menaces en temps rÃ©el qui combine l'analyse de logs systÃ¨mes et la dÃ©tection de fraude financiÃ¨re. Le systÃ¨me utilise Apache Spark Streaming pour traiter les donnÃ©es en temps rÃ©el depuis Kafka et les stocker dans Elasticsearch pour visualisation dans Kibana.

âœ¨ FonctionnalitÃ©s Principales
ğŸ” DÃ©tection multi-menaces : SQL Injection, XSS, Brute Force SSH, Path Traversal

ğŸ’³ DÃ©tection de fraude carding avec gÃ©olocalisation

ğŸ“Š Visualisation temps rÃ©el avec Kibana et cartes gÃ©ographiques

âš¡ Traitement streaming avec Spark Structured Streaming

ğŸ³ Conteneurisation complÃ¨te avec Docker

ğŸ”” Alertes automatiques et corrÃ©lation d'Ã©vÃ©nements

ğŸ—ï¸ Architecture


Composants
Kafka : Bus de messages pour l'ingestion des logs

Spark Streaming : Traitement temps rÃ©el des donnÃ©es

Elasticsearch : Stockage et indexation des alertes

Kibana : Visualisation et tableaux de bord

Syslog-ng : Collecte et parsing des logs systÃ¨mes

Zookeeper : Coordination des services Kafka

ğŸ“¦ PrÃ©requis
SystÃ¨me
Docker 20.0+

Docker Compose 2.0+

8GB RAM minimum

20GB espace disque libre

RÃ©seau
Ports disponibles : 5601, 9200, 9092, 8081, 4040, 2181

ğŸš€ Installation Rapide
1. Cloner le Repository
bash
git clone https://github.com/Skanderbnamor/tp.git
cd tp
2. DÃ©marrer l'Infrastructure
bash
# Lancer tous les conteneurs
./start-all-containers.sh

# Ou manuellement
docker-compose up -d
3. VÃ©rifier les Services
bash
# VÃ©rifier l'Ã©tat des conteneurs
docker-compose ps

# VÃ©rifier les logs
docker-compose logs --follow
ğŸ® Utilisation
DÃ©marrer la DÃ©tection
bash
# Lancer le job Spark Streaming
./start-detection.sh
Simuler des Attaques
bash
# Attaque brute force SSH
./generate-attack.sh

# Attaques web (SQLi, XSS, etc.)
./generate-web-attacks.sh

# Fraude carding mondiale
./generate-carding-attack.sh
AccÃ©der aux Interfaces
Service	URL	Description
Kibana	http://localhost:5601	Tableaux de bord et visualisation
Spark UI	http://localhost:4040	Monitoring des jobs Spark
Spark Master	http://localhost:8081	Interface cluster Spark
Elasticsearch	http://localhost:9200	API de recherche
ğŸ“ Structure du Projet
text
tp/
â”œâ”€â”€ ğŸ“Š docker-compose.yml          # Orchestration des conteneurs
â”œâ”€â”€ ğŸ”§ syslog-ng.conf              # Configuration Syslog-ng
â”œâ”€â”€ âš¡ spark_fraud_detection.py    # Job Spark principal
â”œâ”€â”€ ğŸš€ start-all-containers.sh    # Script de dÃ©marrage complet
â”œâ”€â”€ ğŸ” start-detection.sh         # Lancement de la dÃ©tection
â”œâ”€â”€ ğŸ¯ generate-attack.sh         # Simulation brute force
â”œâ”€â”€ ğŸŒ generate-web-attacks.sh    # Simulation attaques web
â””â”€â”€ ğŸ’³ generate-carding-attack.sh # Simulation fraude carding
ğŸ“Š Configuration Kibana
1. CrÃ©er l'Index Pattern
Allez sur http://localhost:5601

Stack Management â†’ Index Patterns

CrÃ©er le pattern : security_events

SÃ©lectionner @timestamp comme champ temporel

2. Importer les Dashboards
Exemple de visualisations Ã  crÃ©er :

Carte des attaques gÃ©olocalisÃ©es

Graphique des types d'attaques

Timeline des Ã©vÃ©nements

Top 10 des IPs attaquantes

ğŸ”§ API Elasticsearch
Rechercher les Alertes RÃ©centes
bash
curl -X GET "http://localhost:9200/security_events/_search" -H 'Content-Type: application/json' -d'
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "now-1h"
      }
    }
  },
  "sort": [{ "@timestamp": "desc" }]
}'
Statistiques des Attaques
bash
curl -X GET "http://localhost:9200/security_events/_search" -H 'Content-Type: application/json' -d'
{
  "size": 0,
  "aggs": {
    "attacks_by_type": {
      "terms": {
        "field": "attack_type.keyword"
      }
    }
  }
}'
ğŸ“ˆ Monitoring
VÃ©rifier la SantÃ© des Services
bash
# Script de santÃ© inclus
./health-check.sh

# VÃ©rifier manuellement
docker-compose ps
curl http://localhost:9200/_cluster/health
MÃ©triques ClÃ©s
DÃ©bit Kafka : Messages/segond traitÃ©s

Latence Spark : Temps de traitement

Taux de DÃ©tection : Alertes gÃ©nÃ©rÃ©es

Couverture GÃ©ographique : Pays touchÃ©s

ğŸ› DÃ©pannage
ProblÃ¨mes Courants
âŒ Les conteneurs ne dÃ©marrent pas

bash
# VÃ©rifier les ports
sudo netstat -tulpn | grep -E ':(5601|9200|9092)'

# Nettoyer et redÃ©marrer
docker-compose down
docker system prune -f
./start-all-containers.sh
âŒ Spark ne trouve pas les dÃ©pendances

bash
# Forcer le tÃ©lÃ©chargement des JARs
docker exec -u 0 spark-master bash -c "mkdir -p /home/spark/.ivy2 && chown -R spark:spark /home/spark/.ivy2"
âŒ Kafka non accessible

bash
# VÃ©rifier les topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# RecrÃ©er les topics
docker exec kafka kafka-topics --create --topic syslogs --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092
Logs et Debugging
bash
# Voir tous les logs
docker-compose logs --follow

# Logs spÃ©cifiques Ã  un service
docker-compose logs spark-master
docker-compose logs kafka

# VÃ©rifier les erreurs Spark
docker exec spark-master tail -f /opt/spark/logs/spark--org.apache.spark.deploy.master.Master-*.out
ğŸ¤ Contribuer
DÃ©veloppement
Fork le projet

CrÃ©er une branche feature (git checkout -b feature/AmazingFeature)

Commit les changements (git commit -m 'Add some AmazingFeature')

Push sur la branche (git push origin feature/AmazingFeature)

Ouvrir une Pull Request

Tests
bash
# Lancer toutes les simulations
./generate-attack.sh
./generate-web-attacks.sh
./generate-carding-attack.sh

# VÃ©rifier les donnÃ©es dans Kibana
ğŸ“„ Licence
Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

ğŸ‘¥ Auteurs
Skander Ben Amor - DÃ©veloppement initial

ğŸ™ Remerciements
Apache Spark pour le moteur de streaming

Elastic pour la stack ELK

Confluent pour les images Kafka

Docker pour la conteneurisation
